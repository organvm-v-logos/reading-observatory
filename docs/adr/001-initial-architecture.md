# ADR 001: Initial Architecture Decisions

**Status**: Accepted
**Date**: 2026-02-17
**Decision makers**: @4444J99
**Sprint**: LOGOS

## Context

reading-observatory needs to store curated bibliographies, manage a list of RSS/Atom feed subscriptions, aggregate those feeds on a schedule, and match incoming articles against the system's active themes. We need to choose formats for data storage and tools for the aggregation pipeline.

The repository is part of ORGAN-V: Logos, the public-process and discourse layer of the eight-organ system. It must integrate with the essay pipeline and be maintainable by a single operator without requiring infrastructure beyond what GitHub provides.

## Decisions

### Decision 1: YAML for Bibliography Entries

**Choice**: YAML

**Alternatives considered**:

- **BibTeX**: Industry standard for academic bibliographies. Rejected because BibTeX's syntax is optimized for LaTeX integration, which we do not need. Its field names are fixed and do not accommodate custom fields like `relevance` and `collections` without non-standard extensions. Parsing BibTeX reliably in Python requires dedicated libraries with their own quirks. Most importantly, BibTeX entries are not human-friendly to read or write without editor support.

- **JSON**: Structurally adequate but less pleasant to write by hand. JSON does not support comments, which matters for a file that humans will edit directly. JSON's strict syntax (mandatory quotes on keys, no trailing commas) makes hand-editing error-prone. Since bibliography entries are authored by humans, not generated by machines, the authoring experience matters.

- **Markdown tables**: Compact for display but terrible for structured data. No support for multi-line fields (relevance, notes), no type information, and parsing is fragile. Would require a custom parser for every consumer.

**Rationale**: YAML supports comments, multi-line strings, custom fields, and is natively readable by both humans and the Python ecosystem. The `pyyaml` library is mature and ubiquitous. YAML's indentation-based structure makes bibliography entries scannable in a text editor without tooling. The eight-organ system already uses YAML extensively (seed.yaml files, configuration), so it is a familiar format.

### Decision 2: OPML for Feed Subscriptions

**Choice**: OPML (Outline Processor Markup Language)

**Alternatives considered**:

- **YAML list of URLs**: Simpler but non-standard. Would not be importable into feed readers for manual browsing. Would require documenting a custom schema.

- **JSON feed list**: Same objections as JSON for bibliographies, plus the loss of interoperability with feed readers.

- **Plain text file**: Maximally simple but provides no structure for metadata (feed title, associated collection, HTML URL).

**Rationale**: OPML is the standard format for exchanging feed subscription lists. Every major feed reader can import and export OPML. Using OPML means the subscription list can be loaded into any feed reader for manual browsing, which is valuable during the curation process. The format supports hierarchical grouping, which we use to organize feeds by collection. The XML syntax is more verbose than YAML, but for a file that changes infrequently (adding a feed is a deliberate curatorial act), the verbosity is acceptable.

### Decision 3: Python for Feed Aggregation

**Choice**: Python 3.10+ with `feedparser` and `pyyaml`

**Alternatives considered**:

- **Node.js**: Would work but adds a runtime dependency that the rest of ORGAN-V does not require. The `feedparser` equivalent in Node (`rss-parser`) is less battle-tested.

- **Shell script with curl + jq**: Feasible for simple fetching but inadequate for XML/Atom parsing, keyword extraction, and scoring. Would quickly become unmaintainable.

- **Go binary**: Excellent for distribution but overkill for a script that runs once a week. The compilation step adds friction for quick iteration.

**Rationale**: Python is already present in the system's CI environment and on the operator's development machine. The `feedparser` library handles the full range of RSS and Atom feed quirks (encoding, date formats, malformed XML) that would otherwise require significant effort to handle. Python's string processing and YAML handling are mature. A single `.py` file with two dependencies is the simplest viable implementation.

### Decision 4: Keyword Matching over ML-Based Relevance Scoring

**Choice**: TF-IDF keyword matching against essay tags and bibliography tags

**Alternatives considered**:

- **Embedding-based semantic search**: Use sentence embeddings (e.g., from a local model or API) to compute semantic similarity between feed items and the system's themes. Rejected because it requires either a model download (hundreds of MB), an API key and ongoing cost, or both. The quality improvement over keyword matching is marginal at our current scale (dozens of feeds, not thousands).

- **LLM-based classification**: Send each feed item to an LLM with a prompt asking "is this relevant to [collection]?" Rejected for the same cost/complexity reasons, plus the latency of API calls for potentially hundreds of feed items per week.

- **No matching (surface everything)**: Simply present all new feed items for human review. Rejected because the whole point of the observatory is to reduce the volume of material the human operator must review. Without filtering, the feed list would need to be kept artificially small, defeating the purpose of broad monitoring.

**Rationale**: Keyword matching using TF-IDF is computationally trivial, requires no external dependencies beyond what Python provides, produces deterministic results, and is transparent (you can see exactly which keywords caused a match). At our current scale of ~50 monitored feeds producing ~200 items per week, keyword matching with a conservative threshold produces a manageable stream of 10-20 surfaced items. If scale increases by an order of magnitude, we can revisit this decision (see ADR template for future escalation).

## Consequences

- Bibliography files are human-editable YAML, which means contributors need to know YAML syntax. This is acceptable given the system's audience.
- The OPML feed list is XML, which is less pleasant to edit than YAML, but the interoperability benefit outweighs the editing friction.
- The Python aggregator has exactly two pip dependencies (`feedparser`, `pyyaml`), keeping the dependency surface minimal.
- Keyword matching will miss semantically relevant articles that do not share vocabulary with the tag set. This is an acceptable false-negative rate for a system that prioritizes precision over recall.
- All data is stored in flat files (YAML, JSON, OPML), which means no database to maintain but also no query language for complex lookups. At current scale, `grep` and Python scripts are sufficient.
